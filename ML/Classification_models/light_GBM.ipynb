{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **XGBOOST'dan train hızını artırmak için üretilmiş.**\n",
    "* **level-wise yerine leaf-wise süreci işlemektedir.**\n",
    "* **XGBOOST karar ağacı yatay şekilde kullanırılken göre bir arama gerçekleştirirken Light GBM splitlere ağaçların kendilerine  odaklanmaktadır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression  #lojistic algoritması\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier  #KNneighbors algoritması\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC #destek vektor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns   #grafik çizmek için\n",
    "import matplotlib.pyplot as plt #grafik çizmek için\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "y = df[\"Outcome\"]\n",
    "X = df.drop(\"Outcome\", axis = 1)\n",
    "X_test, X_train, y_test, y_train = train_test_split(X,y,test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\mutlu\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mutlu\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mutlu\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mutlu\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mutlu\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m           LGBMClassifier\n",
       "\u001b[1;31mString form:\u001b[0m   \n",
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "           impo <...> ambda=0.0, silent=True,\n",
       "           subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\mutlu\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\n",
       "\u001b[1;31mDocstring:\u001b[0m      LightGBM classifier.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Construct a gradient boosting model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "boosting_type : string, optional (default='gbdt')\n",
       "    'gbdt', traditional Gradient Boosting Decision Tree.\n",
       "    'dart', Dropouts meet Multiple Additive Regression Trees.\n",
       "    'goss', Gradient-based One-Side Sampling.\n",
       "    'rf', Random Forest.\n",
       "num_leaves : int, optional (default=31)\n",
       "    Maximum tree leaves for base learners.\n",
       "max_depth : int, optional (default=-1)\n",
       "    Maximum tree depth for base learners, <=0 means no limit.\n",
       "learning_rate : float, optional (default=0.1)\n",
       "    Boosting learning rate.\n",
       "    You can use ``callbacks`` parameter of ``fit`` method to shrink/adapt learning rate\n",
       "    in training using ``reset_parameter`` callback.\n",
       "    Note, that this will ignore the ``learning_rate`` argument in training.\n",
       "n_estimators : int, optional (default=100)\n",
       "    Number of boosted trees to fit.\n",
       "subsample_for_bin : int, optional (default=200000)\n",
       "    Number of samples for constructing bins.\n",
       "objective : string, callable or None, optional (default=None)\n",
       "    Specify the learning task and the corresponding learning objective or\n",
       "    a custom objective function to be used (see note below).\n",
       "    Default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
       "class_weight : dict, 'balanced' or None, optional (default=None)\n",
       "    Weights associated with classes in the form ``{class_label: weight}``.\n",
       "    Use this parameter only for multi-class classification task;\n",
       "    for binary classification task you may use ``is_unbalance`` or ``scale_pos_weight`` parameters.\n",
       "    Note, that the usage of all these parameters will result in poor estimates of the individual class probabilities.\n",
       "    You may want to consider performing probability calibration\n",
       "    (https://scikit-learn.org/stable/modules/calibration.html) of your model.\n",
       "    The 'balanced' mode uses the values of y to automatically adjust weights\n",
       "    inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.\n",
       "    If None, all classes are supposed to have weight one.\n",
       "    Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)\n",
       "    if ``sample_weight`` is specified.\n",
       "min_split_gain : float, optional (default=0.)\n",
       "    Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
       "min_child_weight : float, optional (default=1e-3)\n",
       "    Minimum sum of instance weight (hessian) needed in a child (leaf).\n",
       "min_child_samples : int, optional (default=20)\n",
       "    Minimum number of data needed in a child (leaf).\n",
       "subsample : float, optional (default=1.)\n",
       "    Subsample ratio of the training instance.\n",
       "subsample_freq : int, optional (default=0)\n",
       "    Frequence of subsample, <=0 means no enable.\n",
       "colsample_bytree : float, optional (default=1.)\n",
       "    Subsample ratio of columns when constructing each tree.\n",
       "reg_alpha : float, optional (default=0.)\n",
       "    L1 regularization term on weights.\n",
       "reg_lambda : float, optional (default=0.)\n",
       "    L2 regularization term on weights.\n",
       "random_state : int or None, optional (default=None)\n",
       "    Random number seed.\n",
       "    If None, default seeds in C++ code will be used.\n",
       "n_jobs : int, optional (default=-1)\n",
       "    Number of parallel threads.\n",
       "silent : bool, optional (default=True)\n",
       "    Whether to print messages while running boosting.\n",
       "importance_type : string, optional (default='split')\n",
       "    The type of feature importance to be filled into ``feature_importances_``.\n",
       "    If 'split', result contains numbers of times the feature is used in a model.\n",
       "    If 'gain', result contains total gains of splits which use the feature.\n",
       "**kwargs\n",
       "    Other parameters for the model.\n",
       "    Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
       "\n",
       "    .. warning::\n",
       "\n",
       "        \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "n_features_ : int\n",
       "    The number of features of fitted model.\n",
       "classes_ : array of shape = [n_classes]\n",
       "    The class label array (only for classification problem).\n",
       "n_classes_ : int\n",
       "    The number of classes (only for classification problem).\n",
       "best_score_ : dict or None\n",
       "    The best score of fitted model.\n",
       "best_iteration_ : int or None\n",
       "    The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
       "objective_ : string or callable\n",
       "    The concrete objective used while fitting this model.\n",
       "booster_ : Booster\n",
       "    The underlying Booster of this model.\n",
       "evals_result_ : dict or None\n",
       "    The evaluation results if ``early_stopping_rounds`` has been specified.\n",
       "feature_importances_ : array of shape = [n_features]\n",
       "    The feature importances (the higher, the more important the feature).\n",
       "\n",
       "Note\n",
       "----\n",
       "A custom objective function can be provided for the ``objective`` parameter.\n",
       "In this case, it should have the signature\n",
       "``objective(y_true, y_pred) -> grad, hess`` or\n",
       "``objective(y_true, y_pred, group) -> grad, hess``:\n",
       "\n",
       "    y_true : array-like of shape = [n_samples]\n",
       "        The target values.\n",
       "    y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The predicted values.\n",
       "    group : array-like\n",
       "        Group/query data, used for ranking task.\n",
       "    grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the first order derivative (gradient) for each sample point.\n",
       "    hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
       "        The value of the second order derivative (Hessian) for each sample point.\n",
       "\n",
       "For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
       "If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
       "and you should group grad and hess in this way as well.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?lgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7486033519553073"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgbm_model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \"learning_rate\": [0.01, 0.1, 0.002],\n",
    "         \"max_depth\": [2, 7, 10],\n",
    "         \"n_estimators\":[500, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   28.7s finished\n"
     ]
    }
   ],
   "source": [
    "lgbm_cv=GridSearchCV(lgbm_model, params,cv = 10, n_jobs = -1, verbose = 2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final\n",
    "lgbm_tuned = LGBMClassifier(learning_rate = 0.01, max_depth = 7, n_estimators = 500).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7337057728119181"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgbm_tuned.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Değişken Önem sırası"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28309a63d48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "important = pd.Series(lgbm_tuned.feature_importances_, index = X_train.columns ).sort_values(ascending= False)\n",
    "sns.barplot(x=important, y=important.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
